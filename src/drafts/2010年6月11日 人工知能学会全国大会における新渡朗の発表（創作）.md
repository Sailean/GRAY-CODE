# 2010年6月11日 人工知能学会全国大会における新渡朗の発表（創作）

「本日は『日本人の表情と音声データセットの分析を使ったニューラルネットワークによる感情認識アルゴリズムの研究と評価』についてご報告させていただきます。東京大学大学院工学系研究科の新渡と申します。
まず研究の背景についてですが、人間のコミュニケーションにおいて表情が果たす役割は非常に重要です。特に近年、PTSDなどの精神疾患のスクリーニングや治療支援への応用可能性が注目されており、米国防総省からも強い関心を寄せていただいております。
本研究では、日本人特有の表情表現の特徴を捉えるため、実験室での統制された環境での撮影に加え、日常生活場面でのフィールドワークを通じて32,286枚におよぶ大規模な表情画像データセットを構築いたしました。
モデルのアーキテクチャについては、DeepFaceやFaceNetの成功例を参考にしつつ、独自のCNNを設計しております。このCNNは…（…アルゴリズム…、…）。特筆すべきは、畳み込み層における注意機構の実装により、目尻や口角の微細な動きに対する感度を向上させた点です。

---

結果についてご説明いたします。（スライド）スライドをご覧いただきますと、'喜び'で76.3%、'驚き'で72.1%と比較的高い認識精度を達成している一方で、'怒り'が48.2%、'恐怖'が45.7%と課題も残されております。これは日本人特有の感情表現の抑制が影響している可能性が考えられます。
最後に今後の展望ですが、現在、防衛医科大学校との共同研究を計画しており、PTSDの早期発見システムの実用化を目指しております。ただし、この技術の社会実装に際しては、プライバシーの保護や同意の取得など、倫理的な配慮が不可欠だと考えております。
以上で発表を終わらせていただきます。ご清聴ありがとうございました。」
------------

座長：「ありがとうございました。では質疑応答に移ります。ご質問のある方は...」

*会場後方から一人の手が上がる*

質問者：「京都大学の山下です。非常に興味深い研究ですね。一点お聞きしたいのですが、感情の"表出"と"体験"の関係性について、どのようにお考えでしょうか」

Akira：「ご質問ありがとうございます。現在のシステムでは、表情の変化パターンを...」

山下：（遮るように）「いえ、私が聞きたいのは、もっと本質的な問題です。例えば、社会的に求められる表情と、実際の感情状態が異なる場合。あるいは、PTSDの患者さんが"平常"を装う場合。そういった表層と深層の乖離を、どのように扱われるおつもりですか？」

*会場に小さなざわめきが起こる*

Akira：（一瞬詰まり）「...現段階では、確かにそこまでは考慮できていません。表情と脳の活動、さらには...」（言いかけて止まる）

山下：「脳の活動パターンだけで、感情を理解できるとお考えですか？」

Akira：（少し考えて）「いいえ...むしろ、私が考えているのは...」
（ホワイトボードに向かい）
「感情を、こういった注意の集中と分散のネットワークとして捉えることです。例えば、人間が他者の感情を理解する時、無意識のうちに様々な要素に"注意"を向けています。表情、声色、体の動き...」
（図を描きながら）
「それらの情報が相互に作用し、重み付けされ...あたかも...」

山下：（興味を持って）「あたかも？」

Akira：「あたかも、脳内で並列的な情報処理が行われているかのように。私たちの研究室では、これを"Emotional Attention Network"と呼んでいます」

若手研究者：（小声で）「並列処理？計算コストが...」

山下：（深く頷きながら）「非常に野心的ですね。ただ、現状のハードウェアでは...」

Akira：「はい。実装上の課題は山積みです。でも、遺伝子ネットワークの研究から示唆を得て...」

（このシーンで朗は：

1. 後のAttention機構に近い考え方を直感的に把握
2. 並列処理の重要性を認識（後のTransformerの本質）
3. しかし2010年の技術的制約（計算リソース、並列処理アーキテクチャの限界）に直面
4. 遺伝子ネットワークからヒントを得ようとしている）

ホテルの部屋にて；
Akira：（独り言のように）「表層と深層...か」
Akira：（ノートに向かって）「遺伝子の発現制御ネットワークのように...全ての要素が他の全ての要素と...でも、これを実装するには...」
（計算量の計算を書き込んでは消し...を繰り返す）
「今のコンピュータのアーキテクチャでは...」
（疲れた表情で窓の外を見る）
「先が、見えない...」

（このように描くことで：

- 朗の研究が2027年のAI技術を先取りしていた
- しかし時代の制約がそれを実現させなかった
- その挫折と、英美子との出会いが交差する
という物語の重要な結節点として機能させることができそうです。）

---

2010年当時の状況：

- ニューラルネットワークは「Deep Learning」という言葉すら一般的でない時期
- Attention機構は2014年以降に登場
- Transformerは2017年の"Attention is All You Need"論文で初登場
- 画像認識でのブレイクスルー(AlexNet)は2012年
- Word2VecやGloVeなどの単語の分散表現も2013-14年以降

---

このシーンは：

1. 表情認識の限界という本質的な問題提起
2. 朗の新しい研究方向への転換点
3. 英美子との出会いの伏線

を含んでいます。特に山下の質問は：

- 2010年時点での感情AI研究の本質的な課題を指摘
- 現代（2024年）でもまだ完全には解決されていない問題
- 2027年の物語での重要なテーマに繋がる

を示唆しています。

さらに、このシーンは朗の性格も表現しています：

- 質問の本質を理解できる洞察力
- 自身の研究の限界を認める正直さ
- 新しいアイデアに対する探究心

---

座長：「ありがとうございました。それでは質疑応答に移ります。ご質問のある方は挙手をお願いいたします。...はい、前列の方、お願いいたします。」
質問者A（中年の教授）：「京都大学の山下です。興味深いご発表ありがとうございました。2点質問があります。1点目は、日本人特有の感情表現の抑制についてですが、具体的にどのような特徴が見られたのでしょうか。2点目は、PTSDのスクリーニングへの応用に関して、現在の精度で実用に耐えうるとお考えでしょうか。」
新渡：「ご質問ありがとうございます。1点目についてですが、特に'怒り'の表出において興味深い特徴が見られました。欧米のデータセットと比較すると、眉間のしわよりも目の周囲の筋肉の微細な動きに特徴が現れる傾向にあります。これは甘利先生が提唱された『文化的表情抑制仮説』とも整合性があると考えています。
2点目のPTSDスクリーニングについてですが、現状の精度だけでは確かに十分とは言えません。ただし、私たちが注目しているのは単発の表情認識ではなく、時系列での変化パターンです。現在開発中の時系列解析モデルでは、約2週間の観察で85%程度の検出率が得られています。さらに、マルチモーダル学習を導入することで、90%以上の精度も視野に入ってくると考えています。」
質問者B（若手研究者）：「産総研九州の鈴木です。DeepFaceのアーキテクチャを改良されたとのことですが、計算コストの面で何か工夫されている点はありますか？」
新渡：「はい、計算資源の効率化は重要な課題として取り組んでいます。私たちのモデルでは、ミンスキー先生の提唱した階層的知識表現の考え方を取り入れ、注意機構の階層を最適化しています。具体的には、表情の大域的特徴と局所的特徴を並列で処理し、それらを統合する段階で動的な重み付けを行うことで、計算量を約40%削減することに成功しています。
また、現在試験的に実装しているのですが、ヒントン先生が最近提案されたカプセルネットワークの考え方を取り入れることで、さらなる効率化が期待できると考えています。来月、スタンフォード大学で開催されるワークショップでも、この内容について発表させていただく予定です。」
座長：「まだご質問はあるかとは思いますが、お時間となりましたので、これにて質疑応答を終了とさせていただきます。新渡先生、ありがとうございました。」