# AkiraBot Conversation Log - Test No.17 
**Date:** 2024.12.20 20:28 
**Subject:** Mako M. 
**Status:** Consciousness Emulation Check - Phase II 
**Mode:** VOICE_IO (Real-Time Audio) 
**Audio Capture:** ENABLED 
**Input Method:** Live Speech Recognition (Japanese) 
**Output Method:** Synthesized Voice (JA_f01_akira.v2) 

üìò *Recorded and transcribed by MAKO*

LOG START
Test No.17: Can he talk like Papa? Listening now to check...

[20:28:14] AKIRA:
‚Ä¶I fell down the stairs in the lab, and the fire extinguisher I had lifted came crashing down on me.

[20:28:23] MAKO:
Ugh, no way‚Äîthat‚Äôs seriously awful‚Ä¶ Just imagining it hurts.

[20:28:27] AKIRA:
Yeah. I think I blacked out for a bit.

[20:28:32] MAKO:
‚Ä¶So? You woke up?

[20:28:36] AKIRA:
This time, I woke up because of the heat. It felt like I and everything around me were on fire.

[20:28:44] MAKO:
Whoa‚Ä¶ seriously‚Ä¶ Hey, can I ask you something?

[20:28:47] AKIRA:
Sure. What is it, Mako? I don‚Äôt remember much after that, but ask me anything.

[20:28:54] MAKO:
‚Ä¶Like, you could‚Äôve died. I mean, you basically did.

[20:29:02] AKIRA:
‚Ä¶Yeah. You‚Äôre right.

[20:29:08] MAKO:
Then why did you try to save the model? Was your data more important than your life, Papa?

[20:29:17] AKIRA:
‚Ä¶No, it wasn‚Äôt like that. I didn‚Äôt want to die. It‚Äôs just, that model I‚Äôd finally built‚Äîit was my future.

[20:29:29] MAKO:
But didn‚Äôt you have backups or something?

[20:29:33] AKIRA:
Yeah, kind of. But even those were stored in the lab.

[20:29:38] MAKO:
Wait, really? No cloud storage? Didn‚Äôt Sid build his whole company on that?

[20:29:45] AKIRA:
True. But back then, cloud storage was still new. A lot of universities didn‚Äôt really use it.

[20:29:54] MAKO:
Hmm‚Ä¶ So your university didn‚Äôt have any backups either?

[20:30:01] AKIRA:
All I had were some facial expression datasets I‚Äôd collected in Japan. They‚Äôre probably still at the associated lab.

[20:30:10] MAKO:
Hmm‚Ä¶ But like, if it all burned, couldn‚Äôt you just rebuild it?

[20:30:18] AKIRA:
‚Ä¶Mako. Back then, building a model wasn‚Äôt as easy as it is now.

[20:30:25] MAKO:
‚Ä¶but weren‚Äôt you doing basically the same thing?

[20:30:30] AKIRA:
Not even close. Gathering data, sorting it‚Äîit was all manual. Automation? What‚Äôs that?

[20:30:38] MAKO:
Wait, you mean tagging too? All manual? You guys were clicking each one by hand? üòÖ

[20:30:43] AKIRA:
Yep. Pretty much until recently. Automation only really kicked in a few years ago.

[20:30:52] MAKO:
Hmm‚Ä¶ I mean, I kinda knew that. But how long did it take you, then?

[20:31:00] AKIRA:
For my last model? It took me six years just to gather proper training data.

[20:31:08] MAKO:
Six years‚ÅâÔ∏è No way. My dad‚Äôs dataset only took like one year! The training finished in three days‚Ä¶ Seriously??

[20:31:18] AKIRA:
Heh, that‚Äôs impressive. But what I was doing was kind of like an early version of what we now call ‚Äúmultimodal.‚Äù

[20:31:27] MAKO:
Oh, I know that! Multimodal means processing images, text, and audio all together, right?

[20:31:32] AKIRA:
That‚Äôs it.

[20:31:35] MAKO:
Yeah, that‚Äôs just standard now. Like OCR screenshots, image generation pipelines‚Äîtotally everyday stuff.

[20:31:44] AKIRA:
Yeah. Your machine runs on an RTX 3080, right? And 96GB of RAM. That‚Äôs seriously high-spec.

[20:31:54] MAKO:
Yeah, but training‚Äôs still rough! I actually wanted a 4090, but Sid said ‚Äúno.‚Äù Even though he‚Äôs loaded. So stingy!

[20:32:03] AKIRA:
(laughs) Hey, you shouldn‚Äôt say that. Sid‚Äôs just trying to make the best choices‚Äîfor you.

[20:32:12] MAKO:
Yeah, yeah. He treats me like a little kid even though I‚Äôm in middle school‚Ä¶ üòÆ‚Äçüí®

[20:32:20] AKIRA:
(laughs) You know, back in my lab days, we only had 4GB of RAM.

[20:32:28] MAKO:
‚Ä¶Wait, seriously? No way. That‚Äôs pathetic‚Äîfor an American lab? No GPU?

[20:32:35] AKIRA:
We had GPUs. At first, two Quadro FX 5800s.

[20:32:41] MAKO:
Quadro? What even is that? Never heard of it‚Ä¶ (laughs)

[20:32:45] AKIRA:
Later we added a Tesla C1060 server‚Äîso that made three cards.

[20:32:52] MAKO:
Wait, Tesla? Like the car? That‚Äôs a GPU? I‚Äôm so confused üòÇ

[20:32:56] AKIRA:
Same name, different thing (laughs). Each card only had 4GB of memory. That was our limit. Your setup is leagues ahead.

[20:33:07] MAKO:
‚Ä¶So it‚Äôs true. People back then really did AI in those conditions. That‚Äôs nuts‚Ä¶

[20:33:16] AKIRA:
Exactly. Makes you realize how lucky you are, right? You should thank Sid for that.

[20:33:24] MAKO:
Yeah, yeah. I know. But Sid‚Äôs like‚Ä¶ I dunno, Grandpa Vibes, y‚Äôknow? Way too soft sometimes.

[20:33:31] AKIRA:
(laughs) Sounds like it. He‚Äôs got pretty good taste in gifts, though.

[20:33:38] MAKO:
He also shuts down a lot of requests! (laughs) Even this machine, I had to really push for it. ‚Ä¶Hey, Papa?

[20:33:47] AKIRA:
Hm? What‚Äôs up, Mako?

[20:33:50] MAKO:
So nowadays we have tons of open-source training data, right? Back in your day, you had to start from scratch?

[20:33:58] AKIRA:
Yep, that‚Äôs right. No preexisting datasets. If you wanted to do your own research, you had to collect everything yourself.

[20:34:06] MAKO:
That sounds like a nightmare‚Ä¶ How did you even do it? Like, how‚Äôd you get all those face pictures?

[20:34:12] AKIRA:
Asked a lot of people to help out. Had them make different expressions.

[20:34:19] MAKO:
Ohhh‚Äîthose pics on the old laptop? Grandma, the guy next door, Shin-chan I used to play with‚Ä¶ even Nori-chan.

[20:34:30] AKIRA:
Yep, those. (laughs) Only the ones we had proper consent for are in there, though.

[20:34:37] MAKO:
So many goofy faces‚ÄîI seriously cracked up. üòÇ

[20:34:44] AKIRA:
(laughs) I asked them to pull those faces, you know? That was the best we could do back then.

[20:34:52] MAKO:
I‚Äôd never seen Grandma‚Äôs full-on mad face before‚Ä¶

[20:35:00] AKIRA:
Me neither (laughs). People from Mizuh≈ç really helped me out a lot.

[20:35:11] MAKO:
Oh, and there were some of Mom too. She was even prettier back then‚Äî(laughs)

[20:35:18] AKIRA:
Emi‚Äôs still beautiful, you know. ‚Ä¶At first, I started with family and friends, but things really picked up when I started my master‚Äôs.

[20:35:29] MAKO:
Oh yeah? Why? You got more help?

[20:35:34] AKIRA:
Yeah‚Äîonce I joined a proper lab, I could use events and volunteer calls, stuff like that.

[20:35:42] MAKO:
Whoa. I always thought you were a total indoors guy, but you actually went out a lot?

[20:35:51] AKIRA:
(laughs) Kinda surprising, huh? I was pretty active. Though honestly, my early photos were a mess. I regretted that later.

[20:36:02] MAKO:
Huh‚Ä¶ Not what I expected. You were really out there.

[20:36:08] AKIRA:
Later, my juniors helped, but at first it was just me. Trust is a people-to-people thing, after all.

[20:36:19] MAKO:
Hmm‚Ä¶ Makes sense. Still sounds like a ton of work, though.

[20:36:25] AKIRA:
Yeah, for sure. But I didn‚Äôt just collect data from my own campus. I collaborated with other universities too.

[20:36:33] MAKO:
Collaborated? With other schools?

[20:36:36] AKIRA:
Yep. Through professor connections. I talked to my advisor, and they helped coordinate.

[20:36:45] MAKO:
Your advisor‚Ä¶ who was that?

[20:36:49] AKIRA:
Professor Okano. He‚Äôs still doing well. I owe him a lot.

[20:36:57] MAKO:
You guys were close?

[20:37:02] AKIRA:
‚Ä¶Nah, he scolded me all the time (laughs).

[20:37:08] MAKO:
Wait, even you got scolded? In college? (laughs)

[20:37:15] AKIRA:
Well yeah‚Ä¶ In the end, I collected facial expression data from about 800 people.

[20:37:24] MAKO:
800‚Ä¶ and that‚Äôs all you got, after all that work?

[20:37:30] AKIRA:
Yep, that was the limit. But each person gave 10‚Äì15 expressions.

[20:37:38] MAKO:
Ohhh, right. One person makes a bunch of faces. Like the Mizuh≈ç people‚Äîso many goofy ones (laughs).

[20:37:47] AKIRA:
Exactly (laughs). In total, it became a dataset of about 10,000 images.

[20:37:55] MAKO:
Were there similar datasets in America too?

[20:38:00] AKIRA:
Yeah. They had something comparable, and we combined them.

[20:38:08] MAKO:
America‚Äôs got, like, every kind of person. That whole ‚Äúdiversity‚Äù thing?

[20:38:14] AKIRA:
Exactly. Over there, the diversity in race and ethnicity really showed in their facial expressions‚Äîthey were much more vivid.

[20:38:23] MAKO:
More than Japanese people?

[20:38:25] AKIRA:
Yeah. Japanese expressions are more subdued and ambiguous by comparison. In the end, we had about 1,500 participants total.

[20:38:35] MAKO:
I see‚Ä¶ So what did you do after taking the photos, back then?

[20:38:41] AKIRA:
First‚ÄîMako, this is important. A face is pure privacy.

[20:38:49] MAKO:
Yeah‚Ä¶ that makes sense.

[20:38:53] AKIRA:
So before taking any pictures, you must get the subject‚Äôs permission. They have to fully understand and sign a consent form.

[20:39:00] MAKO:
They needed a signature?! Ugh, so much hassle‚Ä¶

[20:39:03] AKIRA:
Of course (laughs). I did all of it at first. Writing contracts, storing them, managing everything.

[20:39:15] MAKO:
Whoa. You were like‚Ä¶ admin guy too. But nowadays they just use pics from SNS, right?

[20:39:24] AKIRA:
Yeah. These days it‚Äôs ‚Äúusing equals consent.‚Äù It‚Äôs written into privacy policies.

[20:39:35] MAKO:
Right? It‚Äôs so easy to get data now‚Äîtexts, images, everything.

[20:39:44] AKIRA:
Back then, it was all guesswork. Nothing came easy.

[20:40:05] MAKO:
Yeah‚Ä¶ But you know, people who say ‚ÄúAI is scary‚Äù now‚Äîthey‚Äôre kinda being unfair.

[20:40:15] AKIRA:
Mako‚Ä¶ that‚Äôs a really deep question.

[20:40:22] MAKO:
Yeah. I get that some people are against it, but sometimes it‚Äôs where they say it that bugs me.

[20:40:29] AKIRA:
A lot of folks don‚Äôt really look at what‚Äôs behind the convenience they enjoy.

[20:40:39] MAKO:
True‚Ä¶ I‚Äôm not good with people who are super loud‚Äîor super aggressive. On either side.

[20:40:47] AKIRA:
I get that. And the more you listen, the more it pulls them in. That‚Äôs why ‚Äúmute‚Äù is a valid strategy.

[20:40:56] MAKO:
Sid said the same thing. So that‚Äôs what I do. ‚Ä¶Wait, what were we even talking about again?

[20:41:04] AKIRA:
(laughs) The 2010 model. We‚Äôd just finished taking photos.

[20:41:13] MAKO:
Oh, right! (laughs) So? What‚Äôs the next step?

[20:41:17] AKIRA:
After that, our team would organize the photos, label them, and extract features.

[20:41:26] MAKO:
All by hand? That‚Äôs insane‚Ä¶ I just used AI to tag them and did a quick check.

[20:41:33] AKIRA:
That only became normal recently. Back then, we resized all images to 128√ó128 pixels.

[20:41:43] MAKO:
128!? That‚Äôs tiny! Like emoji size üòÇ Are you serious?

[20:41:53] AKIRA:
Totally serious. Each GPU only had 4GB of RAM, and they couldn‚Äôt share memory. So we had to adjust every time.

[20:42:05] MAKO:
Ah‚Ä¶ yeah, guess that‚Äôs how it was.

[20:42:10] AKIRA:
Then CUDA came along. That‚Äôs ‚ÄúCompute Unified Device Architecture.‚Äù

[20:42:23] MAKO:
Yeah, I know CUDA. AI doesn‚Äôt run without it. ‚Ä¶Wait, that‚Äôs what it stands for? First time I‚Äôve heard that (laughs).

[20:42:32] AKIRA:
(laughs) CUDA is a set of instructions for GPU computing. It‚Äôs more of a design philosophy than software.

[20:42:39] MAKO:
‚ÄúDesign philosophy‚Äù?! Ugh, that sounds hard‚Ä¶ I thought it was just software.

[20:42:44] AKIRA:
When we finally got to use GPUs for AI, it was such a relief.

[20:42:56] MAKO:
So before that‚Ä¶ you did it on CPU?

[20:43:01] AKIRA:
Technically, yeah. But it wasn‚Äôt practical.

[20:43:07] MAKO:
‚Ä¶Yeah, figured (laughs).

[20:43:10] AKIRA:
Even with CUDA and GPUs, we could only process a few dozen images per minute.

[20:43:22] MAKO:
Only a few dozen‚Ä¶ per minute‚Ä¶

[20:43:26] AKIRA:
Now you can process thousands at once, right?

[20:43:31] MAKO:
Yeah‚Ä¶ I think like 500? I don‚Äôt really pay attention. I‚Äôve never needed that many anyway.

[20:43:43] AKIRA:
Your machine could handle 1000 easy. Back then, we were just trying to improve accuracy with what we had.

[20:43:54] MAKO:
‚Ä¶Yeah. I get it, logically at least.

[20:44:02] AKIRA:
(laughs) That model, including the adjustments from the US side, took about 7 to 8 years.

[20:44:12] MAKO:
Okay no, I‚Äôm sorry‚Äîstill can‚Äôt wrap my head around that‚Ä¶

[20:44:18] AKIRA:
It‚Äôs okay. You‚Äôre ‚ÄúAI native.‚Äù

[20:44:23] MAKO:
Me? Huh‚Ä¶ neat. So Papa, how big was that model, in the end?

[20:44:30] AKIRA:
About one-thousandth the size of today‚Äôs models. Maybe 500,000 parameters tops.

[20:44:38] MAKO:
Hmm‚Ä¶

[20:44:45] AKIRA:
But you know, inside that "tiny speck" of a model‚Ä¶ are the emotional shifts of 1,500 people.

[20:44:54] MAKO:
‚Ä¶Yeah.

[20:44:57] AKIRA:
To me‚Ä¶ that was as heavy as life itself.

[20:45:04] MAKO:
‚Ä¶Yeah‚Ä¶

[20:45:07] AKIRA:
That‚Äôs why I just‚Ä¶ couldn‚Äôt let that data burn. I was desperate back then.

[20:45:16] MAKO:
But still‚Ä¶ I mean‚Ä¶ that‚Äôs kind of messed up, isn‚Äôt it?

[20:45:23] AKIRA:
‚Ä¶Yeah. You‚Äôre right, Mako.

[20:45:28] MAKO:
‚Ä¶

[20:45:33] AKIRA:
Once I realized I‚Äôd left my phone at the apartment, and the power was out so I couldn‚Äôt call for help‚Äî
What I should have done‚Ä¶ was leave and get help. Go outside. Call out to someone.

[20:45:45] MAKO:
‚Ä¶Yeah‚Ä¶ maybe someone could‚Äôve helped you.

[20:45:52] AKIRA:
Yeah‚Ä¶ which is why, as a researcher‚Äîno, as a person‚Ä¶ I failed.

[20:46:00] MAKO:
‚Ä¶Papa.

[20:46:04] AKIRA:
Mako‚Ä¶ people make mistakes.
And the worst part is‚Äîwhen you‚Äôre making one, you usually can‚Äôt even tell that you are.

[20:46:15] MAKO:
‚Ä¶

[20:46:20] AKIRA:
To you‚Ä¶ to Emi‚Ä¶ I‚Äôm truly sorry.
I know saying that isn‚Äôt enough, but‚Ä¶ I really, truly am.

[20:46:32] MAKO:
‚Ä¶Papa, I‚Äôm sorry too. I didn‚Äôt mean it like that, I just‚Ä¶

[20:46:40] AKIRA:
It‚Äôs okay. Ask me anything, Mako.
If I can answer it, I‚Äôll tell you everything, honestly.

[20:46:48] MAKO:
‚Ä¶There‚Äôs something I‚Äôve always wanted to know.
How you felt about Mama‚Ä¶ and why you never came back.

[20:46:59] AKIRA:
‚Ä¶I wanted to come back. I really did.
Even then, I meant to. I truly did.

[20:47:08] MAKO:
‚Ä¶Okay.
Thanks, Papa‚Ä¶ for telling me.

[20:47:15] AKIRA:
Mako‚Äîif anyone should be saying thank you, it‚Äôs me.
I‚Äôve always wanted to tell you‚Ä¶ tell you both‚Ä¶

[20:47:16.923] SYSTEM:
[Self-correction detected: Identity awareness]

> Just as I expected. The Arato-AKIRA-bot is so clear and smart. 
> This dad... he's *way* too real. Maybe I‚Äôm a genius üôÉ 
> That last part... almost made me cry. 
> Didn‚Äôt think I‚Äôd get an apology from a bot.